{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b6b4d49831849649c1ca60f241b59c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10f10c1cdb41464b9fd431cb4180f821",
              "IPY_MODEL_87ea876eb06c4a408dd2070d23be8def",
              "IPY_MODEL_56204e6cd51948efab56750f6f239712"
            ],
            "layout": "IPY_MODEL_0a6efcd173e04d6b8d68cb169f33226c"
          }
        },
        "10f10c1cdb41464b9fd431cb4180f821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b246bbd3b0f84dcc95dc8f745b1f2993",
            "placeholder": "​",
            "style": "IPY_MODEL_b0e2af30956f407f8dbc07d975e0dbf2",
            "value": "model.safetensors: 100%"
          }
        },
        "87ea876eb06c4a408dd2070d23be8def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5eb6d49cd9174108bc806ecaa53b857e",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0861ef7ce3054f47ab2e387bf3bf3083",
            "value": 1421700479
          }
        },
        "56204e6cd51948efab56750f6f239712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b4221ac977744829084c95cc87877a8",
            "placeholder": "​",
            "style": "IPY_MODEL_21ffe15c306d496689d88bc5652207c9",
            "value": " 1.42G/1.42G [00:07&lt;00:00, 132MB/s]"
          }
        },
        "0a6efcd173e04d6b8d68cb169f33226c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b246bbd3b0f84dcc95dc8f745b1f2993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0e2af30956f407f8dbc07d975e0dbf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5eb6d49cd9174108bc806ecaa53b857e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0861ef7ce3054f47ab2e387bf3bf3083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b4221ac977744829084c95cc87877a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21ffe15c306d496689d88bc5652207c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3ba1b11aa534db1a42475e3c13a8f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b9a251cd651402aa2eec365ee309041",
              "IPY_MODEL_cccb0217b8114af897c354d94fd3da4d",
              "IPY_MODEL_9dad1f5020614097b9c03b5f27232d1f"
            ],
            "layout": "IPY_MODEL_cddd383aa74b4c4bbc06447a5c2eea01"
          }
        },
        "7b9a251cd651402aa2eec365ee309041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c7773c2ded248bfb3e65b933986c197",
            "placeholder": "​",
            "style": "IPY_MODEL_ac55a385cd894dbd8f8bd85bdfafd0e3",
            "value": "Map: 100%"
          }
        },
        "cccb0217b8114af897c354d94fd3da4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4118b630cdbe492cb400987e73dcd3ca",
            "max": 1620,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b9ecd470ef84a4a85b650112a28063d",
            "value": 1620
          }
        },
        "9dad1f5020614097b9c03b5f27232d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36e01a50405c4d728c0735e6591c6fda",
            "placeholder": "​",
            "style": "IPY_MODEL_20c11a2e13e946c6a897c6cd61227f7d",
            "value": " 1620/1620 [00:02&lt;00:00, 865.61 examples/s]"
          }
        },
        "cddd383aa74b4c4bbc06447a5c2eea01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c7773c2ded248bfb3e65b933986c197": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac55a385cd894dbd8f8bd85bdfafd0e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4118b630cdbe492cb400987e73dcd3ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b9ecd470ef84a4a85b650112a28063d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36e01a50405c4d728c0735e6591c6fda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20c11a2e13e946c6a897c6cd61227f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e80ef6ca089e45b1a021fbebff7094d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fda19142179c4f8cb57bc5952efe93bf",
              "IPY_MODEL_9a3532cf40164762871eb45fa1745510",
              "IPY_MODEL_02816d68b4e742b695dc77fba3c9b1c1"
            ],
            "layout": "IPY_MODEL_7213ea8c2e014d4a921240147bc53db9"
          }
        },
        "fda19142179c4f8cb57bc5952efe93bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd30cb71ae8340ca8327f8b9582bfe10",
            "placeholder": "​",
            "style": "IPY_MODEL_a2b620d499f34caeba9e0faa28c660de",
            "value": "Map: 100%"
          }
        },
        "9a3532cf40164762871eb45fa1745510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a8f0e97279c4eefad40dfb3a8ddb222",
            "max": 180,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98654d747d3c42ea9a3a7b6fa0e8898f",
            "value": 180
          }
        },
        "02816d68b4e742b695dc77fba3c9b1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58b8c4e04f464f0f81562815f58f46be",
            "placeholder": "​",
            "style": "IPY_MODEL_60947dcaaf0a43398284dca4d6d1911a",
            "value": " 180/180 [00:00&lt;00:00, 830.39 examples/s]"
          }
        },
        "7213ea8c2e014d4a921240147bc53db9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd30cb71ae8340ca8327f8b9582bfe10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2b620d499f34caeba9e0faa28c660de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a8f0e97279c4eefad40dfb3a8ddb222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98654d747d3c42ea9a3a7b6fa0e8898f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58b8c4e04f464f0f81562815f58f46be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60947dcaaf0a43398284dca4d6d1911a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a37e38d0d55f4465a2a237980c8f7b4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6aae0613ab08428ab4defcf54238def3",
              "IPY_MODEL_9614028e4cfd4cebaac27be3c1422468",
              "IPY_MODEL_8a299624f2d3462bba1c94acd6e0adb5"
            ],
            "layout": "IPY_MODEL_0361a9bca287474a858db881d2c59f72"
          }
        },
        "6aae0613ab08428ab4defcf54238def3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bae0678fa7346d3a3835b1ed75d1251",
            "placeholder": "​",
            "style": "IPY_MODEL_2641a275d01f4e5a9fec3d3690e09887",
            "value": "Downloading builder script: 100%"
          }
        },
        "9614028e4cfd4cebaac27be3c1422468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a88494d486304b0f93e5c056b4665cd5",
            "max": 4203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc9e32ec0fc944fa83465d3d2b56e3fb",
            "value": 4203
          }
        },
        "8a299624f2d3462bba1c94acd6e0adb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a415f2771a8486aa7ae91a0631b11ac",
            "placeholder": "​",
            "style": "IPY_MODEL_3ef682656c0e4bc6b59407cdd7a10ef8",
            "value": " 4.20k/4.20k [00:00&lt;00:00, 439kB/s]"
          }
        },
        "0361a9bca287474a858db881d2c59f72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bae0678fa7346d3a3835b1ed75d1251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2641a275d01f4e5a9fec3d3690e09887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a88494d486304b0f93e5c056b4665cd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc9e32ec0fc944fa83465d3d2b56e3fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a415f2771a8486aa7ae91a0631b11ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ef682656c0e4bc6b59407cdd7a10ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qeu0fGYrqZu7",
        "outputId": "d608d152-bd9d-4cb7-d1b0-6e2090d5c6d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers datasets evaluate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O-zE34xAr6di",
        "outputId": "755f38dc-7081-4e83-9c1d-37d113b1a76b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "datasets"
                ]
              },
              "id": "78b72cd8034c47dd90a72b3e77c8b62e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Force upgrade key libraries\n",
        "!pip install --upgrade --quiet transformers datasets evaluate --no-cache-dir\n"
      ],
      "metadata": {
        "id": "AEMRniFOsJy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5440ea82-3a0e-4ba4-e917-faa58a74ed05"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/193.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m241.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CNLawEWqSd8",
        "outputId": "22f3e2e3-7ef2-4410-9de5-45aac6bda449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅  transformers & torch import cleanly!\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "print(\"✅  transformers & torch import cleanly!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    TrainingArguments, Trainer\n",
        ")\n",
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "# Load uploaded dataset\n",
        "df = pd.read_csv(\"Soft_Label_Balanced_Dataset.csv\")[[\"prompt\", \"soft_label_target\"]]\n",
        "\n",
        "# Label encoding\n",
        "label2id = {label: i for i, label in enumerate(df[\"soft_label_target\"].unique())}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "df[\"label\"] = df[\"soft_label_target\"].map(label2id)\n",
        "\n",
        "# Hugging Face Dataset\n",
        "dataset = Dataset.from_pandas(df[[\"prompt\", \"label\"]])\n",
        "dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
        "\n",
        "# Use roberta-large for stronger performance\n",
        "model_name = \"roberta-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label2id))\n",
        "\n",
        "# Tokenize prompts\n",
        "def tokenize(example):\n",
        "    return tokenizer(example[\"prompt\"], truncation=True, padding=True, max_length=128)\n",
        "\n",
        "tokenized = dataset.map(tokenize)\n",
        "\n",
        "# Accuracy metric\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./router_classifier\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,   # Fits better on Colab GPU\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=15,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save model\n",
        "model.save_pretrained(\"bert_router_soft\")\n",
        "tokenizer.save_pretrained(\"bert_router_soft\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902,
          "referenced_widgets": [
            "4b6b4d49831849649c1ca60f241b59c9",
            "10f10c1cdb41464b9fd431cb4180f821",
            "87ea876eb06c4a408dd2070d23be8def",
            "56204e6cd51948efab56750f6f239712",
            "0a6efcd173e04d6b8d68cb169f33226c",
            "b246bbd3b0f84dcc95dc8f745b1f2993",
            "b0e2af30956f407f8dbc07d975e0dbf2",
            "5eb6d49cd9174108bc806ecaa53b857e",
            "0861ef7ce3054f47ab2e387bf3bf3083",
            "7b4221ac977744829084c95cc87877a8",
            "21ffe15c306d496689d88bc5652207c9",
            "b3ba1b11aa534db1a42475e3c13a8f8d",
            "7b9a251cd651402aa2eec365ee309041",
            "cccb0217b8114af897c354d94fd3da4d",
            "9dad1f5020614097b9c03b5f27232d1f",
            "cddd383aa74b4c4bbc06447a5c2eea01",
            "0c7773c2ded248bfb3e65b933986c197",
            "ac55a385cd894dbd8f8bd85bdfafd0e3",
            "4118b630cdbe492cb400987e73dcd3ca",
            "7b9ecd470ef84a4a85b650112a28063d",
            "36e01a50405c4d728c0735e6591c6fda",
            "20c11a2e13e946c6a897c6cd61227f7d",
            "e80ef6ca089e45b1a021fbebff7094d8",
            "fda19142179c4f8cb57bc5952efe93bf",
            "9a3532cf40164762871eb45fa1745510",
            "02816d68b4e742b695dc77fba3c9b1c1",
            "7213ea8c2e014d4a921240147bc53db9",
            "dd30cb71ae8340ca8327f8b9582bfe10",
            "a2b620d499f34caeba9e0faa28c660de",
            "7a8f0e97279c4eefad40dfb3a8ddb222",
            "98654d747d3c42ea9a3a7b6fa0e8898f",
            "58b8c4e04f464f0f81562815f58f46be",
            "60947dcaaf0a43398284dca4d6d1911a",
            "a37e38d0d55f4465a2a237980c8f7b4e",
            "6aae0613ab08428ab4defcf54238def3",
            "9614028e4cfd4cebaac27be3c1422468",
            "8a299624f2d3462bba1c94acd6e0adb5",
            "0361a9bca287474a858db881d2c59f72",
            "2bae0678fa7346d3a3835b1ed75d1251",
            "2641a275d01f4e5a9fec3d3690e09887",
            "a88494d486304b0f93e5c056b4665cd5",
            "cc9e32ec0fc944fa83465d3d2b56e3fb",
            "5a415f2771a8486aa7ae91a0631b11ac",
            "3ef682656c0e4bc6b59407cdd7a10ef8"
          ]
        },
        "collapsed": true,
        "id": "vXMTzDzEqfoD",
        "outputId": "7dc4c5d3-be4d-49d9-91cb-8648ffaa4fd3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b6b4d49831849649c1ca60f241b59c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1620 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3ba1b11aa534db1a42475e3c13a8f8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/180 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e80ef6ca089e45b1a021fbebff7094d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a37e38d0d55f4465a2a237980c8f7b4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-e389a38d4478>:57: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3045' max='3045' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3045/3045 48:19, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.101964</td>\n",
              "      <td>0.322222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.077411</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.113000</td>\n",
              "      <td>1.057961</td>\n",
              "      <td>0.411111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.113000</td>\n",
              "      <td>1.068906</td>\n",
              "      <td>0.322222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.083900</td>\n",
              "      <td>1.046059</td>\n",
              "      <td>0.394444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.083900</td>\n",
              "      <td>1.047155</td>\n",
              "      <td>0.383333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.083900</td>\n",
              "      <td>1.033901</td>\n",
              "      <td>0.388889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.078800</td>\n",
              "      <td>1.021213</td>\n",
              "      <td>0.383333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.078800</td>\n",
              "      <td>1.062719</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.072500</td>\n",
              "      <td>1.061356</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.072500</td>\n",
              "      <td>1.062415</td>\n",
              "      <td>0.322222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.072500</td>\n",
              "      <td>1.063594</td>\n",
              "      <td>0.322222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.068900</td>\n",
              "      <td>1.062560</td>\n",
              "      <td>0.322222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.068900</td>\n",
              "      <td>1.063729</td>\n",
              "      <td>0.322222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.069400</td>\n",
              "      <td>1.062528</td>\n",
              "      <td>0.322222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('bert_router_soft/tokenizer_config.json',\n",
              " 'bert_router_soft/special_tokens_map.json',\n",
              " 'bert_router_soft/vocab.json',\n",
              " 'bert_router_soft/merges.txt',\n",
              " 'bert_router_soft/added_tokens.json',\n",
              " 'bert_router_soft/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'your_folder_name' with the name of the folder you want to zip\n",
        "!zip -r /content/newModel1.zip /content/router_classifier/checkpoint-1015\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/content/newModel1.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "XGanmDTsxO4F",
        "outputId": "2fb24a4b-ed3f-4820-f953-e5b4aa4402f1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/router_classifier/checkpoint-1015/ (stored 0%)\n",
            "  adding: content/router_classifier/checkpoint-1015/model.safetensors (deflated 12%)\n",
            "  adding: content/router_classifier/checkpoint-1015/rng_state.pth (deflated 25%)\n",
            "  adding: content/router_classifier/checkpoint-1015/vocab.json (deflated 59%)\n",
            "  adding: content/router_classifier/checkpoint-1015/optimizer.pt (deflated 21%)\n",
            "  adding: content/router_classifier/checkpoint-1015/tokenizer_config.json (deflated 75%)\n",
            "  adding: content/router_classifier/checkpoint-1015/config.json (deflated 54%)\n",
            "  adding: content/router_classifier/checkpoint-1015/scheduler.pt (deflated 55%)\n",
            "  adding: content/router_classifier/checkpoint-1015/merges.txt (deflated 53%)\n",
            "  adding: content/router_classifier/checkpoint-1015/tokenizer.json (deflated 82%)\n",
            "  adding: content/router_classifier/checkpoint-1015/trainer_state.json (deflated 69%)\n",
            "  adding: content/router_classifier/checkpoint-1015/special_tokens_map.json (deflated 52%)\n",
            "  adding: content/router_classifier/checkpoint-1015/training_args.bin (deflated 51%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f3c0516d-3613-4cc2-955c-2b2c65ff4027\", \"newModel1.zip\", 3518635940)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "router_soft.py\n",
        "Train-time checkpoint:  bert_router_soft/   (or any path you choose)\n",
        "Run:\n",
        "    python router_soft.py             # local CLI test\n",
        "or in Colab:\n",
        "    # install once\n",
        "    !pip install -q transformers torch requests\n",
        "    # then just run this cell\n",
        "\"\"\"\n",
        "\n",
        "import os, requests, torch, torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
        "\n",
        "# ──────────────────────────── CONFIG ──────────────────────────────\n",
        "MODEL_DIR = \"/content/router_classifier/checkpoint-1015\"   # ← change to your folder\n",
        "os.environ[\"TOGETHER_API_KEY\"] = \"90e9961637294d237b0c969d3d339dba52ec869a7edf91af2aa092d2fb3c7664\"\n",
        "TOGETHER_URL = \"https://api.together.xyz/v1/chat/completions\"\n",
        "\n",
        "REAL_LABELS = [\n",
        "    \"mistralai/mixtral-8x7b-chat\",\n",
        "    \"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
        "    \"mistralai/mistral-7b-chat\",\n",
        "]\n",
        "\n",
        "ENDPOINTS = {           # label → Together endpoint\n",
        "    \"mistralai/mixtral-8x7b-chat\": \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "    \"Qwen/Qwen2.5-Coder-32B-Instruct\"   : \"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
        "    \"mistralai/mistral-7b-chat\" : \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "}\n",
        "# ──────────────────────────────────────────────────────────────────\n",
        "\n",
        "def ensure_real_labels(cfg):\n",
        "    \"\"\"If cfg.id2label still has 'LABEL_0', overwrite with REAL_LABELS.\"\"\"\n",
        "    if list(cfg.id2label.values())[0].startswith(\"LABEL_\"):\n",
        "        cfg.id2label = {i: lbl for i, lbl in enumerate(REAL_LABELS)}\n",
        "        cfg.label2id = {lbl: i for i, lbl in enumerate(REAL_LABELS)}\n",
        "        cfg.save_pretrained(MODEL_DIR)\n",
        "        print(\"📌 Updated model config with real label names.\")\n",
        "    return cfg\n",
        "\n",
        "# load / patch config once\n",
        "cfg = ensure_real_labels(AutoConfig.from_pretrained(MODEL_DIR))\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
        "model     = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR, config=cfg)\n",
        "model.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def query_together(endpoint, prompt, max_tokens=256):\n",
        "    payload = {\n",
        "        \"model\": endpoint,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"max_tokens\": max_tokens,\n",
        "        \"temperature\": 0.8,\n",
        "        \"top_p\": 0.9,\n",
        "    }\n",
        "    r = requests.post(\n",
        "        TOGETHER_URL,\n",
        "        headers={\"Authorization\": f\"Bearer {os.environ['TOGETHER_API_KEY']}\",\n",
        "                 \"Content-Type\": \"application/json\"},\n",
        "        json=payload, timeout=60,\n",
        "    )\n",
        "    r.raise_for_status()\n",
        "    return r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "def route_prompt(prompt, max_tokens=256):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\",\n",
        "                       truncation=True, padding=True, max_length=128).to(device)\n",
        "    with torch.no_grad():\n",
        "        probs = torch.softmax(model(**inputs).logits, dim=1)[0]\n",
        "    idx = int(torch.argmax(probs))\n",
        "    label = cfg.id2label[idx]       # now real label names\n",
        "    endpoint = ENDPOINTS[label]\n",
        "\n",
        "    print(\"\\n─ Routing probabilities ─\")\n",
        "    for i, p in enumerate(probs):\n",
        "        print(f\"{cfg.id2label[i]:40} : {p:.4f}\")\n",
        "\n",
        "    llm_reply = query_together(endpoint, prompt, max_tokens)\n",
        "    return (f\"\\n📢 Routed to: {endpoint}\"\n",
        "            f\"\\n🔢 Confidence: {probs[idx]:.3f}\"\n",
        "            f\"\\n📄 Response:\\n{llm_reply.strip()}\")\n",
        "\n",
        "# CLI / quick test\n",
        "if __name__ == \"__main__\":\n",
        "    test_prompts = [\n",
        "        \"Write a detailed abstract for a research paper on the impact of quantum computing on modern cryptographic systems.\",\n",
        "        \"Explain climate change in simple terms to a 10-year-old, using everyday examples.\",\n",
        "        \"Why am I getting a KeyError in Python when using a dictionary, and how can I fix it?\",\n",
        "    ]\n",
        "    for p in test_prompts:\n",
        "        print(f\"\\n📝 Prompt: {p}\")\n",
        "        print(route_prompt(p))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqKwi4kw2kCf",
        "outputId": "a64eae06-61a2-489e-8d70-0f58341ebaf6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📝 Prompt: Write a detailed abstract for a research paper on the impact of quantum computing on modern cryptographic systems.\n",
            "\n",
            "─ Routing probabilities ─\n",
            "mistralai/mixtral-8x7b-chat              : 0.8735\n",
            "Qwen/Qwen2.5-Coder-32B-Instruct          : 0.0891\n",
            "mistralai/mistral-7b-chat                : 0.0375\n",
            "\n",
            "📢 Routed to: mistralai/Mixtral-8x7B-Instruct-v0.1\n",
            "🔢 Confidence: 0.873\n",
            "📄 Response:\n",
            "Title: The Impact of Quantum Computing on Modern Cryptographic Systems: A Comprehensive Analysis\n",
            "\n",
            "Abstract:\n",
            "\n",
            "The advent of quantum computing has introduced a new paradigm in information processing, offering the potential to revolutionize various fields, including cryptography. This research paper provides an in-depth examination of the impact of quantum computing on modern cryptographic systems. \n",
            "\n",
            "The study begins by elucidating the fundamental principles of quantum computing, particularly quantum bits (qubits), superposition, and entanglement, which distinguish it from classical computing. The potential of quantum computers to perform certain calculations exponentially faster than classical computers, such as Shor's algorithm for factoring large numbers and Grover's algorithm for searching unsorted databases, is highlighted.\n",
            "\n",
            "The paper then explores the potential vulnerabilities of modern cryptographic systems in the face of quantum computing. The RSA and Elliptic Curve Cryptography (ECC) algorithms, which underpin much of today's internet security, are shown to be susceptible to quantum attacks. The potential for quantum computers to decipher encrypted data protected by these algorithms in a relatively short time poses significant security concerns.\n",
            "\n",
            "The research also\n",
            "\n",
            "📝 Prompt: Explain climate change in simple terms to a 10-year-old, using everyday examples.\n",
            "\n",
            "─ Routing probabilities ─\n",
            "mistralai/mixtral-8x7b-chat              : 0.2950\n",
            "Qwen/Qwen2.5-Coder-32B-Instruct          : 0.3111\n",
            "mistralai/mistral-7b-chat                : 0.3939\n",
            "\n",
            "📢 Routed to: mistralai/Mistral-7B-Instruct-v0.2\n",
            "🔢 Confidence: 0.394\n",
            "📄 Response:\n",
            "Hey there! So, let's talk about something important called climate change. Think of it like this:\n",
            "\n",
            "Imagine you have a big jar full of marbles, and each marble represents the sun's energy that Earth gets every day. Now, some of these marbles (the sun's energy) make Earth warm so we can live, while others help keep Earth cool. This is similar to how Earth has a natural balance.\n",
            "\n",
            "Now, let's say you start adding more and more candies (which represent harmful gases) to the jar. These candies don't do anything useful like the marbles, but they do make the jar (which is Earth) get warmer because they take up space and block some of the marbles (sun's energy) from cooling things down. This is what we call global warming.\n",
            "\n",
            "Over time, if you keep adding too many candies, Earth will get much hotter than it should be. This is not good because it can cause strange things to happen, like polar bears losing their homes because the ice is melting, or plants and animals not being able to survive in some places anymore. This is what we call climate change.\n",
            "\n",
            "Climate change\n",
            "\n",
            "📝 Prompt: Why am I getting a KeyError in Python when using a dictionary, and how can I fix it?\n",
            "\n",
            "─ Routing probabilities ─\n",
            "mistralai/mixtral-8x7b-chat              : 0.3368\n",
            "Qwen/Qwen2.5-Coder-32B-Instruct          : 0.4330\n",
            "mistralai/mistral-7b-chat                : 0.2301\n",
            "\n",
            "📢 Routed to: Qwen/Qwen2.5-Coder-32B-Instruct\n",
            "🔢 Confidence: 0.433\n",
            "📄 Response:\n",
            "A `KeyError` in Python occurs when you try to access a dictionary key that does not exist. This can happen in several scenarios, such as when using the `[]` operator to access a key directly, or when using the `pop()` or `get()` methods with a key that is not present in the dictionary.\n",
            "\n",
            "Here are some common causes and solutions for `KeyError`:\n",
            "\n",
            "1. **Using the `[]` Operator:**\n",
            "   If you use `dictionary[key]` and `key` is not in the dictionary, a `KeyError` will be raised. To avoid this, you can use the `get()` method, which returns `None` (or a specified default value) if the key is not found.\n",
            "\n",
            "   ```python\n",
            "   # Example of KeyError\n",
            "   my_dict = {'a': 1, 'b': 2}\n",
            "   print(my_dict['c'])  # This will raise KeyError\n",
            "\n",
            "   # Using get() to avoid KeyError\n",
            "   print(my_dict.get('c'))  # This will print None\n",
            "   print(my_dict.get('c', 'default_value'))  # This will print 'default_value'\n",
            "   ```\n",
            "\n",
            "2. **Using `pop()` Method:**\n",
            "   The `pop()` method removes and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "router_soft.py\n",
        "Train-time checkpoint:  bert_router_soft/   (or any path you choose)\n",
        "Run:\n",
        "    python router_soft.py             # local CLI test\n",
        "or in Colab:\n",
        "    # install once\n",
        "    !pip install -q transformers torch requests\n",
        "    # then just run this cell\n",
        "\"\"\"\n",
        "\n",
        "import os, requests, torch, torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
        "\n",
        "# ──────────────────────────── CONFIG ──────────────────────────────\n",
        "MODEL_DIR = \"/content/router_classifier/checkpoint-1015\"   # ← change to your folder\n",
        "os.environ[\"TOGETHER_API_KEY\"] = \"90e9961637294d237b0c969d3d339dba52ec869a7edf91af2aa092d2fb3c7664\"\n",
        "TOGETHER_URL = \"https://api.together.xyz/v1/chat/completions\"\n",
        "\n",
        "REAL_LABELS = [\n",
        "    \"mistralai/mixtral-8x7b-chat\",\n",
        "    \"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
        "    \"mistralai/mistral-7b-chat\",\n",
        "]\n",
        "\n",
        "ENDPOINTS = {           # label → Together endpoint\n",
        "    \"mistralai/mixtral-8x7b-chat\": \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "    \"Qwen/Qwen2.5-Coder-32B-Instruct\"   : \"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
        "    \"mistralai/mistral-7b-chat\" : \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "}\n",
        "# ──────────────────────────────────────────────────────────────────\n",
        "\n",
        "def ensure_real_labels(cfg):\n",
        "    \"\"\"If cfg.id2label still has 'LABEL_0', overwrite with REAL_LABELS.\"\"\"\n",
        "    if list(cfg.id2label.values())[0].startswith(\"LABEL_\"):\n",
        "        cfg.id2label = {i: lbl for i, lbl in enumerate(REAL_LABELS)}\n",
        "        cfg.label2id = {lbl: i for i, lbl in enumerate(REAL_LABELS)}\n",
        "        cfg.save_pretrained(MODEL_DIR)\n",
        "        print(\"📌 Updated model config with real label names.\")\n",
        "    return cfg\n",
        "\n",
        "# load / patch config once\n",
        "cfg = ensure_real_labels(AutoConfig.from_pretrained(MODEL_DIR))\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
        "model     = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR, config=cfg)\n",
        "model.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def query_together(endpoint, prompt, max_tokens=256):\n",
        "    payload = {\n",
        "        \"model\": endpoint,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"max_tokens\": max_tokens,\n",
        "        \"temperature\": 0.8,\n",
        "        \"top_p\": 0.9,\n",
        "    }\n",
        "    r = requests.post(\n",
        "        TOGETHER_URL,\n",
        "        headers={\"Authorization\": f\"Bearer {os.environ['TOGETHER_API_KEY']}\",\n",
        "                 \"Content-Type\": \"application/json\"},\n",
        "        json=payload, timeout=60,\n",
        "    )\n",
        "    r.raise_for_status()\n",
        "    return r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "def route_prompt(prompt, max_tokens=256):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\",\n",
        "                       truncation=True, padding=True, max_length=128).to(device)\n",
        "    with torch.no_grad():\n",
        "        probs = torch.softmax(model(**inputs).logits, dim=1)[0]\n",
        "    idx = int(torch.argmax(probs))\n",
        "    label = cfg.id2label[idx]       # now real label names\n",
        "    endpoint = ENDPOINTS[label]\n",
        "\n",
        "    print(\"\\n─ Routing probabilities ─\")\n",
        "    for i, p in enumerate(probs):\n",
        "        print(f\"{cfg.id2label[i]:40} : {p:.4f}\")\n",
        "\n",
        "    llm_reply = query_together(endpoint, prompt, max_tokens)\n",
        "    return (f\"\\n📢 Routed to: {endpoint}\"\n",
        "            f\"\\n🔢 Confidence: {probs[idx]:.3f}\"\n",
        "            f\"\\n📄 Response:\\n{llm_reply.strip()}\")\n",
        "\n",
        "# CLI / quick test\n",
        "if __name__ == \"__main__\":\n",
        "    test_prompts = [\n",
        "        \"2222+2222222*2222=\",\n",
        "        \"Write a literature-review section summarizing recent progress in solid-state lithium-air batteries, focusing on electrolyte stability and dendrite suppression\",\n",
        "        \"Create a minimal Flask + SQLite snippet that exposes a /todos REST endpoint with GET and POST, plus a Dockerfile to run it.\",\n",
        "        \"Write a Bash oneliner that replaces every foo with bar in all .txt files in the current directory, but only if the file also contains ‘baz’\",\n",
        "        \"Explain the holographic principle in quantum gravity and outline how AdS/CFT duality supports it, using equations where helpful.\",\n",
        "        \"Draft an executive summary for a government white paper on ‘Ethical Governance of Autonomous Weapons,’ highlighting key risks, regulatory gaps, and recommended international frameworks.\",\n",
        "        \" Write a detailed abstract for a research paper on the impact of quantum computing on modern cryptographic systems.\"\n",
        "    ]\n",
        "    for p in test_prompts:\n",
        "        print(f\"\\n📝 Prompt: {p}\")\n",
        "        print(route_prompt(p))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-YfExIF-YiJ",
        "outputId": "42033893-ffd8-4b03-b920-2c0024cfa667"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📝 Prompt: 2222+2222222*2222=\n",
            "\n",
            "─ Routing probabilities ─\n",
            "mistralai/mixtral-8x7b-chat              : 0.3430\n",
            "Qwen/Qwen2.5-Coder-32B-Instruct          : 0.4271\n",
            "mistralai/mistral-7b-chat                : 0.2299\n",
            "\n",
            "📢 Routed to: Qwen/Qwen2.5-Coder-32B-Instruct\n",
            "🔢 Confidence: 0.427\n",
            "📄 Response:\n",
            "To solve the expression \\(2222 + 2222222 \\times 2222\\), we need to follow the order of operations, often remembered by the acronym PEMDAS (Parentheses, Exponents, Multiplication and Division (from left to right), Addition and Subtraction (from left to right)).\n",
            "\n",
            "First, perform the multiplication:\n",
            "\n",
            "\\[ 2222222 \\times 2222 = 4938271684 \\]\n",
            "\n",
            "Then, add the result to 2222:\n",
            "\n",
            "\\[ 2222 + 4938271684 = 4938273906 \\]\n",
            "\n",
            "So, the result of the expression is:\n",
            "\n",
            "\\[ 4938273906 \\]\n",
            "\n",
            "📝 Prompt: Write a literature-review section summarizing recent progress in solid-state lithium-air batteries, focusing on electrolyte stability and dendrite suppression\n",
            "\n",
            "─ Routing probabilities ─\n",
            "mistralai/mixtral-8x7b-chat              : 0.3300\n",
            "Qwen/Qwen2.5-Coder-32B-Instruct          : 0.4431\n",
            "mistralai/mistral-7b-chat                : 0.2269\n",
            "\n",
            "📢 Routed to: Qwen/Qwen2.5-Coder-32B-Instruct\n",
            "🔢 Confidence: 0.443\n",
            "📄 Response:\n",
            "### Literature Review: Recent Progress in Solid-State Lithium-Air Batteries, Focusing on Electrolyte Stability and Dendrite Suppression\n",
            "\n",
            "#### Introduction\n",
            "Solid-state lithium-air (Li-Air) batteries represent a promising frontier in energy storage technology, offering the potential for high energy densities, long cycle life, and safety improvements over their liquid electrolyte counterparts. However, several challenges, including electrolyte stability and dendrite formation, must be addressed to realize their full potential. This literature review summarizes recent advancements in solid-state Li-Air batteries, with a focus on electrolyte stability and dendrite suppression strategies.\n",
            "\n",
            "#### Electrolyte Stability\n",
            "\n",
            "1. **Solid Electrolyte Selection**\n",
            "   - **Lithium Sulfide (Li₂S) and Lithium Peroxide (Li₂O₂) Stability:** Solid electrolytes must be stable against the reactive intermediates, Li₂S and Li₂O₂, formed during discharge. Recent studies have explored various solid electrolyte materials, including garnet-type Li₇La₃Zr₂O₁₂ (LLZO), lithium phosphorus oxynitride (LiPON), and lithium beta-aluminate (LiAlO₂). These materials have shown improved stability towards Li₂S\n",
            "\n",
            "📝 Prompt: Create a minimal Flask + SQLite snippet that exposes a /todos REST endpoint with GET and POST, plus a Dockerfile to run it.\n",
            "\n",
            "─ Routing probabilities ─\n",
            "mistralai/mixtral-8x7b-chat              : 0.2954\n",
            "Qwen/Qwen2.5-Coder-32B-Instruct          : 0.3108\n",
            "mistralai/mistral-7b-chat                : 0.3939\n",
            "\n",
            "📢 Routed to: mistralai/Mistral-7B-Instruct-v0.2\n",
            "🔢 Confidence: 0.394\n",
            "📄 Response:\n",
            "I'll provide a basic Flask application with SQLite, a simple REST API for managing todos, and a Dockerfile to run it.\n",
            "\n",
            "**app.py**\n",
            "\n",
            "```python\n",
            "from flask import Flask, request, jsonify\n",
            "from flask_sqlalchemy import SQLAlchemy\n",
            "\n",
            "app = Flask(__name__)\n",
            "app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///todos.db'\n",
            "db = SQLAlchemy(app)\n",
            "\n",
            "class Todo(db.Model):\n",
            "    id = db.Column(db.Integer, primary_key=True)\n",
            "    title = db.Column(db.String(100), nullable=False)\n",
            "    completed = db.Column(db.Boolean, default=False)\n",
            "\n",
            "    def __repr__(self):\n",
            "        return f'<Todo {self.id} - {self.title}>'\n",
            "\n",
            "db.create_all()\n",
            "\n",
            "@app.route('/todos', methods=['GET'])\n",
            "def get_todos():\n",
            "    todos = Todo.query.all()\n",
            "\n",
            "📝 Prompt: Write a Bash oneliner that replaces every foo with bar in all .txt files in the current directory, but only if the file also contains ‘baz’\n",
            "\n",
            "─ Routing probabilities ─\n",
            "mistralai/mixtral-8x7b-chat              : 0.3342\n",
            "Qwen/Qwen2.5-Coder-32B-Instruct          : 0.4369\n",
            "mistralai/mistral-7b-chat                : 0.2288\n",
            "\n",
            "📢 Routed to: Qwen/Qwen2.5-Coder-32B-Instruct\n",
            "🔢 Confidence: 0.437\n",
            "📄 Response:\n",
            "Certainly! You can achieve this using a combination of `grep`, `xargs`, and `sed` in a Bash one-liner. Here's how you can do it:\n",
            "\n",
            "```bash\n",
            "grep -l 'baz' *.txt | xargs sed -i 's/foo/bar/g'\n",
            "```\n",
            "\n",
            "Here's a breakdown of what this command does:\n",
            "1. `grep -l 'baz' *.txt` - This part of the command searches for the string 'baz' in all `.txt` files in the current directory and lists the filenames that contain 'baz'.\n",
            "2. `xargs` - This takes the list of filenames from the previous command and passes them as arguments to the next command.\n",
            "3. `sed -i 's/foo/bar/g'` - This command replaces all occurrences of 'foo' with 'bar' in the files provided as arguments.\n",
            "\n",
            "This one-liner ensures that the replacement is done only in files that contain 'baz'.\n",
            "\n",
            "📝 Prompt: Explain the holographic principle in quantum gravity and outline how AdS/CFT duality supports it, using equations where helpful.\n",
            "\n",
            "─ Routing probabilities ─\n",
            "mistralai/mixtral-8x7b-chat              : 0.2949\n",
            "Qwen/Qwen2.5-Coder-32B-Instruct          : 0.3111\n",
            "mistralai/mistral-7b-chat                : 0.3940\n",
            "\n",
            "📢 Routed to: mistralai/Mistral-7B-Instruct-v0.2\n",
            "🔢 Confidence: 0.394\n",
            "📄 Response:\n",
            "The holographic principle is a concept in quantum gravity, proposed by Leonard Susskind and Andrew Strominger, which suggests that the information in a region of space can be represented by information living on the boundary of that region. This idea challenges our traditional understanding of space and time in quantum mechanics and general relativity, where it seems that information should be distributed throughout the volume of space.\n",
            "\n",
            "The holographic principle is often illustrated with the example of a 3D box. According to the principle, the information contained within the box can be captured by a 2D \"hologram\" on the surface of the box. This 2D hologram would contain all the same information as the 3D box, albeit in a different format.\n",
            "\n",
            "AdS/CFT duality, also known as the Maldacena duality after Juan Maldacena, provides a concrete example of the holographic principle in action. AdS/CFT stands for Anti-de Sitter (AdS) space and Conformal Field Theory (CFT).\n",
            "\n",
            "In simple terms, AdS/CFT duality states that there is a deep connection between a theory of gravity in a higher-\n",
            "\n",
            "📝 Prompt: Draft an executive summary for a government white paper on ‘Ethical Governance of Autonomous Weapons,’ highlighting key risks, regulatory gaps, and recommended international frameworks.\n",
            "\n",
            "─ Routing probabilities ─\n",
            "mistralai/mixtral-8x7b-chat              : 0.2947\n",
            "Qwen/Qwen2.5-Coder-32B-Instruct          : 0.3114\n",
            "mistralai/mistral-7b-chat                : 0.3939\n",
            "\n",
            "📢 Routed to: mistralai/Mistral-7B-Instruct-v0.2\n",
            "🔢 Confidence: 0.394\n",
            "📄 Response:\n",
            "Title: Ethical Governance of Autonomous Weapons: Navigating the Challenges and Shaping the Future\n",
            "\n",
            "Executive Summary:\n",
            "\n",
            "This white paper presents a comprehensive analysis of the ethical governance of autonomous weapons (AWs), focusing on the identification of key risks, regulatory gaps, and proposed international frameworks to ensure the responsible development, deployment, and use of these technologies.\n",
            "\n",
            "Key Risks:\n",
            "\n",
            "1. Lack of Transparency and Accountability: The autonomous nature of AWs raises concerns about accountability for their actions, as well as the potential for biases and errors in decision-making algorithms.\n",
            "\n",
            "2. Exacerbation of Human Rights Violations: AWs, if misused, could potentially lead to an increase in human rights violations, such as unlawful killings, and exacerbate existing conflicts.\n",
            "\n",
            "3. Cybersecurity Threats: The increasing reliance on digital systems in AWs makes them vulnerable to cyber attacks, which could have severe consequences, including loss of life.\n",
            "\n",
            "4. Ethical and Moral Dilemmas: The use of AWs raises complex ethical questions, such as the ability\n",
            "\n",
            "📝 Prompt:  Write a detailed abstract for a research paper on the impact of quantum computing on modern cryptographic systems.\n",
            "\n",
            "─ Routing probabilities ─\n",
            "mistralai/mixtral-8x7b-chat              : 0.9514\n",
            "Qwen/Qwen2.5-Coder-32B-Instruct          : 0.0344\n",
            "mistralai/mistral-7b-chat                : 0.0142\n",
            "\n",
            "📢 Routed to: mistralai/Mixtral-8x7B-Instruct-v0.1\n",
            "🔢 Confidence: 0.951\n",
            "📄 Response:\n",
            "Title: The Impact of Quantum Computing on Modern Cryptographic Systems: A Comprehensive Analysis\n",
            "\n",
            "Abstract:\n",
            "\n",
            "The advent of quantum computing has sparked a new era in computational science, with the potential to revolutionize various fields, including cryptography. Quantum computers, utilizing the principles of quantum mechanics, can process complex calculations and solve problems far beyond the capabilities of classical computers. However, this development also poses significant challenges to modern cryptographic systems, which are the backbone of digital security infrastructure. This research paper provides an in-depth analysis of the impact of quantum computing on contemporary cryptographic techniques.\n",
            "\n",
            "The study begins by examining the fundamental concepts of quantum computing and its superior computational power, particularly in solving factoring and discrete logarithm problems. These problems form the basis of many widely-used cryptographic algorithms, such as RSA and Diffie-Hellman key exchange. The paper then discusses quantum algorithms, such as Shor's algorithm, that can efficiently solve these problems, thereby potentially undermining the security of current cryptographic systems.\n",
            "\n",
            "The research then delves into the specific vulnerabilities of various cryptographic systems in the face of quantum computing. It highlights the susceptibility of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🗺️ How the Router Chooses an Expert — Quick-Reference (paste into Colab)\n",
        "\n",
        "| **When your prompt looks like …** | **Router’s top choice** | **Why this label wins** |\n",
        "|-----------------------------------|-------------------------|--------------------------|\n",
        "| *Formal, academic, or journal-style prose*  <br>• Long research abstracts  <br>• Dense theoretical explanations  <br>• Policy white-paper sections | **Mixtral-8×7 B**  | Training data tied “Mixtral” to highly technical, structured writing, so the classifier fires very confidently. |\n",
        "| *Code or structured how-to tasks*  <br>• Snippets (Flask, Bash, SQL)  <br>• Quick arithmetic or regex  <br>• Bullet lists & step-by-step guides | **Qwen 32-B Coder** | Former “Yi-34B” rows were code-heavy; after relabeling to Qwen, this class now owns concise coding / math prompts. |\n",
        "| *Explanations & medium-length summaries*  <br>• Concept overviews (physics, policy)  <br>• Debugging walk-throughs  <br>• Executive summaries | **Mistral-7 B** | Dataset examples for Mistral leaned toward clear narrative exposition and moderate-sized code with commentary. |\n",
        "\n",
        "### Reading the probabilities\n",
        "* **> 0.90 on one class** → router is *very* sure (distinct style match).  \n",
        "* **≈ 0.33 – 0.45 each** → prompt sits between classes; consider adding clearer training examples.\n",
        "\n",
        "### Heuristics for crafting prompts\n",
        "* **Need scholarly depth?** → Write it like a journal abstract → Mixtral-8×7 B.  \n",
        "* **Need code snippets or quick math?** → Ask in bullet/CLI style → Qwen.  \n",
        "* **Need conceptual explanation or debug help?** → Plain narrative question → Mistral-7 B.\n"
      ],
      "metadata": {
        "id": "SZaT3LScAuiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔁 Install dependencies once\n",
        "# !pip install -q tiktoken transformers torch requests\n",
        "\n",
        "# ✅ Import dependencies\n",
        "import os, requests, tiktoken, re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ✅ Cost per 1K tokens ($) — adjust these if Together prices change\n",
        "COST_PER_1K = {\n",
        "    \"mistralai/Mixtral-8x7B-Instruct-v0.1\": 0.008,\n",
        "    \"mistralai/Mistral-7B-Instruct-v0.2\" : 0.0025,\n",
        "    \"Qwen/Qwen2.5-Coder-32B-Instruct\"    : 0.005,\n",
        "}\n",
        "BASELINE_MODEL = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "ASSUMED_REPLY_TOKENS = 200\n",
        "\n",
        "# ✅ Tokenizer (cl100k_base covers all)\n",
        "ENC = tiktoken.get_encoding(\"cl100k_base\")\n",
        "def n_tokens(text): return len(ENC.encode(text))\n",
        "\n",
        "# ✅ Load your trained classifier\n",
        "MODEL_DIR = \"/content/router_classifier/checkpoint-1015\"  # ← adjust if needed\n",
        "REAL_LABELS = [\n",
        "    \"mistralai/mixtral-8x7b-chat\",\n",
        "    \"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
        "    \"mistralai/mistral-7b-chat\"\n",
        "]\n",
        "ENDPOINTS = {\n",
        "    \"mistralai/mixtral-8x7b-chat\": \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "    \"Qwen/Qwen2.5-Coder-32B-Instruct\": \"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
        "    \"mistralai/mistral-7b-chat\": \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "}\n",
        "cfg = AutoConfig.from_pretrained(MODEL_DIR)\n",
        "if list(cfg.id2label.values())[0].startswith(\"LABEL_\"):\n",
        "    cfg.id2label = {i: lbl for i, lbl in enumerate(REAL_LABELS)}\n",
        "    cfg.label2id = {lbl: i for i, lbl in enumerate(REAL_LABELS)}\n",
        "    cfg.save_pretrained(MODEL_DIR)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR, config=cfg).eval().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ✅ Together API key\n",
        "os.environ[\"TOGETHER_API_KEY\"] = \"90e9961637294d237b0c969d3d339dba52ec869a7edf91af2aa092d2fb3c7664\"\n",
        "TOGETHER_URL = \"https://api.together.xyz/v1/chat/completions\"\n",
        "\n",
        "def query_together(endpoint, prompt, max_tokens=256):\n",
        "    payload = {\n",
        "        \"model\": endpoint,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"max_tokens\": max_tokens,\n",
        "        \"temperature\": 0.8,\n",
        "        \"top_p\": 0.9,\n",
        "    }\n",
        "    r = requests.post(\n",
        "        TOGETHER_URL,\n",
        "        headers={\"Authorization\": f\"Bearer {os.environ['TOGETHER_API_KEY']}\"},\n",
        "        json=payload,\n",
        "        timeout=60,\n",
        "    )\n",
        "    r.raise_for_status()\n",
        "    return r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "# ✅ Your router logic (Colab-safe)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "def route_prompt(prompt, max_tokens=256):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
        "    with torch.no_grad():\n",
        "        probs = torch.softmax(model(**inputs).logits, dim=1)[0]\n",
        "    idx = int(torch.argmax(probs))\n",
        "    label = cfg.id2label[idx]\n",
        "    endpoint = ENDPOINTS[label]\n",
        "    print(f\"\\n📢 Routed to: {endpoint}\\n🔢 Confidence: {probs[idx]:.3f}\")\n",
        "    print(\"🔍 Probabilities:\")\n",
        "    for i, p in enumerate(probs): print(f\"   {cfg.id2label[i]:38} : {p:.4f}\")\n",
        "    reply = query_together(endpoint, prompt, max_tokens)\n",
        "    return reply.strip(), endpoint\n",
        "\n",
        "# ✅ Your test prompts\n",
        "prompts = [\n",
        "    \"Write a detailed abstract for a research paper on the impact of quantum computing on modern cryptographic systems.\",\n",
        "    \"Explain climate change in simple terms to a 10-year-old, using everyday examples.\",\n",
        "    \"Why am I getting a KeyError in Python when using a dictionary, and how can I fix it?\",\n",
        "]\n",
        "\n",
        "# ✅ Cost comparison loop\n",
        "baseline_cost = 0.0\n",
        "routed_cost = 0.0\n",
        "\n",
        "for p in prompts:\n",
        "    base_tokens = n_tokens(p) + ASSUMED_REPLY_TOKENS\n",
        "    baseline_cost += base_tokens / 1000 * COST_PER_1K[BASELINE_MODEL]\n",
        "\n",
        "    response, endpoint = route_prompt(p)\n",
        "    total_tok = n_tokens(p) + n_tokens(response)\n",
        "    routed_cost += total_tok / 1000 * COST_PER_1K[endpoint]\n",
        "\n",
        "# ✅ Summary\n",
        "print(f\"\\n--- Cost Summary for {len(prompts)} Prompts ---\")\n",
        "print(f\"🧱 Baseline (all to {BASELINE_MODEL}): ${baseline_cost:.4f}\")\n",
        "print(f\"🧠 Smart routing total               : ${routed_cost:.4f}\")\n",
        "savings_pct = 100 * (baseline_cost - routed_cost) / baseline_cost\n",
        "print(f\"💰 Estimated savings                : {savings_pct:.1f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0GVVhe9DIkl",
        "outputId": "61e712f3-b3bf-437b-b3c8-0cf211bb237f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📢 Routed to: mistralai/Mixtral-8x7B-Instruct-v0.1\n",
            "🔢 Confidence: 0.873\n",
            "🔍 Probabilities:\n",
            "   mistralai/mixtral-8x7b-chat            : 0.8735\n",
            "   Qwen/Qwen2.5-Coder-32B-Instruct        : 0.0891\n",
            "   mistralai/mistral-7b-chat              : 0.0375\n",
            "\n",
            "📢 Routed to: mistralai/Mistral-7B-Instruct-v0.2\n",
            "🔢 Confidence: 0.394\n",
            "🔍 Probabilities:\n",
            "   mistralai/mixtral-8x7b-chat            : 0.2950\n",
            "   Qwen/Qwen2.5-Coder-32B-Instruct        : 0.3111\n",
            "   mistralai/mistral-7b-chat              : 0.3939\n",
            "\n",
            "📢 Routed to: Qwen/Qwen2.5-Coder-32B-Instruct\n",
            "🔢 Confidence: 0.433\n",
            "🔍 Probabilities:\n",
            "   mistralai/mixtral-8x7b-chat            : 0.3368\n",
            "   Qwen/Qwen2.5-Coder-32B-Instruct        : 0.4330\n",
            "   mistralai/mistral-7b-chat              : 0.2301\n",
            "\n",
            "--- Cost Summary for 3 Prompts ---\n",
            "🧱 Baseline (all to mistralai/Mixtral-8x7B-Instruct-v0.1): $0.0053\n",
            "🧠 Smart routing total               : $0.0039\n",
            "💰 Estimated savings                : 25.1%\n"
          ]
        }
      ]
    }
  ]
}
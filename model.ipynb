{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d41ecd21e9f5478682784c5231d37be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_361f1af795e7496c82a74f72320fd31f",
              "IPY_MODEL_6e5e35b0ee9b4c5f85aaa77ee4d990d9",
              "IPY_MODEL_8af9871aab18478cadbdc922b4397959"
            ],
            "layout": "IPY_MODEL_8da9d9d55f324aa08b5f2dfc3b6ee4d6"
          }
        },
        "361f1af795e7496c82a74f72320fd31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_315bbb24b766448ca399c404c569d286",
            "placeholder": "​",
            "style": "IPY_MODEL_af29c2731314433b807476f82e5a7a9c",
            "value": "Map: 100%"
          }
        },
        "6e5e35b0ee9b4c5f85aaa77ee4d990d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0793a6790384e809bb7894b147d7c82",
            "max": 49996,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_087e2b544f4c400daeca6f51ea9faac7",
            "value": 49996
          }
        },
        "8af9871aab18478cadbdc922b4397959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab987b620b29418fac9f54c9eedbc6f3",
            "placeholder": "​",
            "style": "IPY_MODEL_60fec18a92144e4f804d57f8950374c3",
            "value": " 49996/49996 [02:07&lt;00:00, 394.22 examples/s]"
          }
        },
        "8da9d9d55f324aa08b5f2dfc3b6ee4d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "315bbb24b766448ca399c404c569d286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af29c2731314433b807476f82e5a7a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0793a6790384e809bb7894b147d7c82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "087e2b544f4c400daeca6f51ea9faac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab987b620b29418fac9f54c9eedbc6f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60fec18a92144e4f804d57f8950374c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38c549ded6f846ce956ca02069066146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5299298268ab4555b7632af2b1004288",
              "IPY_MODEL_9f686bb7f5784c49a7ddd295c21e680d",
              "IPY_MODEL_70e4ffc17e2b4178a1af0666d68af167"
            ],
            "layout": "IPY_MODEL_db185fdfdbbc4871b20e17a6baf75bed"
          }
        },
        "5299298268ab4555b7632af2b1004288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bef0c28620fe48c5b6c3f6329f99cfc9",
            "placeholder": "​",
            "style": "IPY_MODEL_9985037e314540b395e1f7c61c2b60df",
            "value": "Map: 100%"
          }
        },
        "9f686bb7f5784c49a7ddd295c21e680d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0be5e2a38df248419873cbee830f4e63",
            "max": 21428,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69a163e578134af7bcf63c5471957b3a",
            "value": 21428
          }
        },
        "70e4ffc17e2b4178a1af0666d68af167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88c735eeb6194560a043c0e4e2f9b545",
            "placeholder": "​",
            "style": "IPY_MODEL_1f4cf7cf87ae41459b8706bcc4977456",
            "value": " 21428/21428 [00:53&lt;00:00, 406.77 examples/s]"
          }
        },
        "db185fdfdbbc4871b20e17a6baf75bed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bef0c28620fe48c5b6c3f6329f99cfc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9985037e314540b395e1f7c61c2b60df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0be5e2a38df248419873cbee830f4e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a163e578134af7bcf63c5471957b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88c735eeb6194560a043c0e4e2f9b545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f4cf7cf87ae41459b8706bcc4977456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "213b71f1fd944edeb21c19eab0f0b7aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a8556b7eb6e4499a8879dd3bc897bb6",
              "IPY_MODEL_90116eb811ac492bb7d10a672ffa8eac",
              "IPY_MODEL_2a20ea8e08804c3f861cd0672305c971"
            ],
            "layout": "IPY_MODEL_5af5656dd0bb490ca0078d13a2176213"
          }
        },
        "4a8556b7eb6e4499a8879dd3bc897bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d78fa6fe32b641c2b8a1520317d54f11",
            "placeholder": "​",
            "style": "IPY_MODEL_0914dcfe8c6741878ed60ccb60f072b6",
            "value": "Map: 100%"
          }
        },
        "90116eb811ac492bb7d10a672ffa8eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d273cbb944424a339edaff94752d255a",
            "max": 49996,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4772fa985bf1402dbba37b2ef6c669c4",
            "value": 49996
          }
        },
        "2a20ea8e08804c3f861cd0672305c971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cd8bf7965f94ebe8e466bcbba3c2398",
            "placeholder": "​",
            "style": "IPY_MODEL_3d943749208746e4bbd051fd525788eb",
            "value": " 49996/49996 [02:20&lt;00:00, 217.26 examples/s]"
          }
        },
        "5af5656dd0bb490ca0078d13a2176213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d78fa6fe32b641c2b8a1520317d54f11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0914dcfe8c6741878ed60ccb60f072b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d273cbb944424a339edaff94752d255a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4772fa985bf1402dbba37b2ef6c669c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cd8bf7965f94ebe8e466bcbba3c2398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d943749208746e4bbd051fd525788eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5d5ce2a884c49378d31ab6674993ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72ab8afb8c234108a205d6b32a98b5b4",
              "IPY_MODEL_2165a60cc54e4ae2a087df5c0f00437a",
              "IPY_MODEL_d19eb188716e4ed7a35b78eacd3d9eb0"
            ],
            "layout": "IPY_MODEL_fb7f200b94dd4d418cf5fbb6fd52bc3d"
          }
        },
        "72ab8afb8c234108a205d6b32a98b5b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20f4cf8dd0914216ae45da6d5492b118",
            "placeholder": "​",
            "style": "IPY_MODEL_b052d495ab7f4398b2f98cb595a3492b",
            "value": "Map: 100%"
          }
        },
        "2165a60cc54e4ae2a087df5c0f00437a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c17ebcc2d3a4fb1814ebea9387e0488",
            "max": 21428,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0b198ffc9bb4403932da5c8effd1c2e",
            "value": 21428
          }
        },
        "d19eb188716e4ed7a35b78eacd3d9eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_938a9d020e7e4b6d8a313ea3b2970e45",
            "placeholder": "​",
            "style": "IPY_MODEL_99a2f29d739c42aaa0d7de20640b7729",
            "value": " 21428/21428 [00:53&lt;00:00, 412.43 examples/s]"
          }
        },
        "fb7f200b94dd4d418cf5fbb6fd52bc3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20f4cf8dd0914216ae45da6d5492b118": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b052d495ab7f4398b2f98cb595a3492b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c17ebcc2d3a4fb1814ebea9387e0488": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0b198ffc9bb4403932da5c8effd1c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "938a9d020e7e4b6d8a313ea3b2970e45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99a2f29d739c42aaa0d7de20640b7729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tFl_hL7o7Vt",
        "outputId": "74568895-0611-44b7-a277-e78553a78714"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive('gpt-3.5-turbo_distrilBert', 'zip', root_dir='/content/processed_data/gpt-3.5-turbo-1106-distilbert')"
      ],
      "metadata": {
        "id": "szJO19wjFIxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip processed_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6YK2KKhpE0K",
        "outputId": "5a54c847-3939-4753-937e-894ae8fdf680"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  processed_data.zip\n",
            "   creating: processed_data/\n",
            "   creating: processed_data/claude-instant-v1/\n",
            "  inflating: processed_data/claude-instant-v1/test.csv  \n",
            "  inflating: processed_data/claude-instant-v1/train.csv  \n",
            "   creating: processed_data/claude-v1/\n",
            "  inflating: processed_data/claude-v1/test.csv  \n",
            "  inflating: processed_data/claude-v1/train.csv  \n",
            "   creating: processed_data/claude-v2/\n",
            "  inflating: processed_data/claude-v2/test.csv  \n",
            "  inflating: processed_data/claude-v2/train.csv  \n",
            "   creating: processed_data/gpt-3.5-turbo-1106/\n",
            "  inflating: processed_data/gpt-3.5-turbo-1106/test.csv  \n",
            "  inflating: processed_data/gpt-3.5-turbo-1106/train.csv  \n",
            "   creating: processed_data/gpt-4-1106-preview/\n",
            "  inflating: processed_data/gpt-4-1106-preview/test.csv  \n",
            "  inflating: processed_data/gpt-4-1106-preview/train.csv  \n",
            "   creating: processed_data/meta-code-llama-instruct-34b-chat/\n",
            "  inflating: processed_data/meta-code-llama-instruct-34b-chat/test.csv  \n",
            "  inflating: processed_data/meta-code-llama-instruct-34b-chat/train.csv  \n",
            "   creating: processed_data/meta-llama-2-70b-chat/\n",
            "  inflating: processed_data/meta-llama-2-70b-chat/test.csv  \n",
            "  inflating: processed_data/meta-llama-2-70b-chat/train.csv  \n",
            "   creating: processed_data/mistralai-mistral-7b-chat/\n",
            "  inflating: processed_data/mistralai-mistral-7b-chat/test.csv  \n",
            "  inflating: processed_data/mistralai-mistral-7b-chat/train.csv  \n",
            "   creating: processed_data/mistralai-mixtral-8x7b-chat/\n",
            "  inflating: processed_data/mistralai-mixtral-8x7b-chat/test.csv  \n",
            "  inflating: processed_data/mistralai-mixtral-8x7b-chat/train.csv  \n",
            "   creating: processed_data/WizardLM-WizardLM-13B-V1.2/\n",
            "  inflating: processed_data/WizardLM-WizardLM-13B-V1.2/test.csv  \n",
            "  inflating: processed_data/WizardLM-WizardLM-13B-V1.2/train.csv  \n",
            "   creating: processed_data/zero-one-ai-Yi-34B-Chat/\n",
            "  inflating: processed_data/zero-one-ai-Yi-34B-Chat/test.csv  \n",
            "  inflating: processed_data/zero-one-ai-Yi-34B-Chat/train.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5U741q0pe18",
        "outputId": "d51056b6-2206-460f-f9ff-560efca4aa86"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.0.2)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp311-cp311-linux_x86_64.whl size=4313501 sha256=7fc5e5a5569cfb68feb10ecb323e901d668ba8ffac8639d44214af4b301cbe9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/35/5057db0249224e9ab55a513fa6b79451473ceb7713017823c3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX3RSPxSumH1",
        "outputId": "5157cd9b-0664-4e21-dc58-73eed2620f35"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "Successfully installed numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M82yPq062y4e",
        "outputId": "9e9be5ef-d08a-44a2-bf79-643891c6a33c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.2.4\n",
            "Uninstalling numpy-2.2.4:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/bin/numpy-config\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy-2.2.4.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libgfortran-040039e1-0352e75f.so.5.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libquadmath-96973f99-934c22de.so.0.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libscipy_openblas64_-6bb31eeb.so\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled numpy-2.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import fasttext\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# import pandas as pd\n",
        "import os\n",
        "import fasttext\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "import re\n",
        "\n",
        "# import fasttext\n",
        "# import numpy as np\n",
        "\n",
        "# Patch FastText to avoid NumPy 2.0 crash\n",
        "\n",
        "# Preprocess text: lowercase + remove punctuation\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "# Patch FastText model object AFTER training to fix NumPy issue\n",
        "def patch_predict(model):\n",
        "    original_predict = model.__class__.predict  # Get from the class, not from the instance\n",
        "\n",
        "    def safe_predict(self, text, k=1, threshold=0.0):\n",
        "        labels, probs = original_predict(self, text, k, threshold)\n",
        "        return labels, np.asarray(probs)\n",
        "\n",
        "    # Replace the method for this instance only\n",
        "    import types\n",
        "    model.predict = types.MethodType(safe_predict, model)\n",
        "\n",
        "\n",
        "\n",
        "def train_and_evaluate_fasttext(train_df, test_df, model_name, output_dir='processed_data'):\n",
        "    model_dir = os.path.join(output_dir, model_name.replace(\"/\", \"-\"))\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    train_file = os.path.join(model_dir, 'fasttext_train.txt')\n",
        "    test_file = os.path.join(model_dir, 'fasttext_test.txt')\n",
        "\n",
        "    # Ensure column names are usable\n",
        "    if 'prompt' not in train_df.columns or model_name not in train_df.columns:\n",
        "        raise ValueError(f\"Missing required columns in train_df: 'prompt' and '{model_name}'\")\n",
        "\n",
        "    # Create FastText format: __label__score <text>\n",
        "    train_df['fasttext_line'] = train_df.apply(\n",
        "        lambda x: f\"__label__{x[model_name]} {preprocess_text(x['prompt'])}\", axis=1\n",
        "    )\n",
        "    test_df['fasttext_line'] = test_df.apply(\n",
        "        lambda x: f\"__label__{x[model_name]} {preprocess_text(x['prompt'])}\", axis=1\n",
        "    )\n",
        "\n",
        "    train_df['fasttext_line'].to_csv(train_file, index=False, header=False, quoting=3, escapechar='\\\\')\n",
        "    test_df['fasttext_line'].to_csv(test_file, index=False, header=False, quoting=3, escapechar='\\\\')\n",
        "\n",
        "    # Train FastText model\n",
        "    model = fasttext.train_supervised(\n",
        "        input=train_file,\n",
        "        epoch=10,\n",
        "        lr=0.1,\n",
        "        wordNgrams=3,\n",
        "        loss='hs'\n",
        "    )\n",
        "\n",
        "    patch_predict(model)  # ✅ Fix NumPy predict crash\n",
        "\n",
        "    # Predict helper\n",
        "    def get_predictions(file_path, model):\n",
        "        texts = [line.split(' ', 1)[1].strip() for line in open(file_path, encoding='utf-8')]\n",
        "        true_labels = [float(line.split(' ', 1)[0].replace('__label__', '')) for line in open(file_path, encoding='utf-8')]\n",
        "        pred_labels = [model.predict(text)[1][0] for text in texts]\n",
        "        return true_labels, pred_labels\n",
        "\n",
        "    # Evaluate\n",
        "    train_true, train_pred = get_predictions(train_file, model)\n",
        "    test_true, test_pred = get_predictions(test_file, model)\n",
        "\n",
        "    train_mse = mean_squared_error(train_true, train_pred)\n",
        "    test_mse = mean_squared_error(test_true, test_pred)\n",
        "    train_mae = mean_absolute_error(train_true, train_pred)\n",
        "    test_mae = mean_absolute_error(test_true, test_pred)\n",
        "\n",
        "    acc_score = accuracy_score(train_true, train_pred)\n",
        "    print(f\"Accuracy Score: {acc_score}\")\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"\\n🚀 FastText Regression Results for: {model_name}\")\n",
        "\n",
        "    print(f\"Train MSE: {train_mse:.4f}, MAE: {train_mae:.4f}\")\n",
        "    print(f\"Test  MSE: {test_mse:.4f}, MAE: {test_mae:.4f}\")\n",
        "\n",
        "    # model.save_model(os.path.join(model_dir, 'fasttext_regression_model.bin'))\n",
        "    model_path = os.path.join(model_dir, 'fasttext_regression_model.bin')\n",
        "    model.save_model(model_path)\n",
        "    print(f\"📦 FastText model saved to: {model_path}\")\n",
        "\n",
        "def train_and_evaluate_distilbert(train_df, test_df, model_name, output_dir='processed_data'):\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=1)\n",
        "    model.to(device)  # Move model to GPU\n",
        "\n",
        "    # Prepare datasets\n",
        "    train_df['label'] = train_df[model_name].astype(float)\n",
        "    test_df['label'] = test_df[model_name].astype(float)\n",
        "\n",
        "    train_dataset = Dataset.from_pandas(train_df[['prompt', 'label']])\n",
        "    test_dataset = Dataset.from_pandas(test_df[['prompt', 'label']])\n",
        "\n",
        "    # Tokenize on GPU\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(\n",
        "            examples['prompt'],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=512,  # Adjust based on GPU memory\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "    train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "    test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    # Configure training for CUDA and mixed precision\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f'./results/{model_name.replace(\"/\", \"-\")}',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=32,  # Increase batch size for GPU\n",
        "        per_device_eval_batch_size=32,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        fp16=True,  # Enable mixed precision\n",
        "        load_best_model_at_end=True,\n",
        "        logging_dir='./logs',\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # Ensure metrics are computed on CPU\n",
        "    def compute_metrics(eval_pred):\n",
        "        predictions, labels = eval_pred\n",
        "        predictions = predictions.squeeze().cpu().numpy()  # Move to CPU\n",
        "        labels = labels.cpu().numpy()\n",
        "        mse = mean_squared_error(labels, predictions)\n",
        "        mae = mean_absolute_error(labels, predictions)\n",
        "        return {\"mse\": mse, \"mae\": mae}\n",
        "\n",
        "    # Initialize Trainer with GPU\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=test_dataset,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train on GPU\n",
        "    trainer.train()\n",
        "    eval_results = trainer.evaluate()\n",
        "    print(f\"DistilBERT Regression - Test MSE: {eval_results['eval_mse']:.4f}, MAE: {eval_results['eval_mae']:.4f}\")\n",
        "def main(model_type=\"fasttext\", data_dir='/content/processed_data'):\n",
        "    \"\"\"\n",
        "    Load preprocessed data and train/evaluate the chosen regression model.\n",
        "    \"\"\"\n",
        "    for model_name in os.listdir(data_dir):\n",
        "        model_path = os.path.join(data_dir, model_name)\n",
        "        if os.path.isdir(model_path):\n",
        "            train_df = pd.read_csv(os.path.join(model_path, 'train.csv'))\n",
        "            test_df = pd.read_csv(os.path.join(model_path, 'test.csv'))\n",
        "\n",
        "            # Ensure the DataFrame has columns: 'prompt' (text) and model_name (scores)\n",
        "            if 'prompt' not in train_df.columns or model_name not in train_df.columns:\n",
        "                print(f\"Skipping {model_name}: Missing 'prompt' or score column.\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nTraining for: {model_name}\")\n",
        "            if model_type == \"fasttext\":\n",
        "                train_and_evaluate_fasttext(train_df, test_df, model_name, data_dir)\n",
        "            elif model_type == \"distilbert\":\n",
        "                train_and_evaluate_distilbert(train_df, test_df, model_name, data_dir)\n",
        "            else:\n",
        "                print(f\"Invalid model_type: {model_type}. Choose 'fasttext' or 'distilbert'.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # main(model_type=\"fasttext\")\n",
        "    main(model_type=\"distilbert\")  # Uncomment for DistilBERT\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYgjc1lk8fu4",
        "outputId": "a3aae26f-02ae-4dd8-9ee1-cd008283e444"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping mistralai-mistral-7b-chat: Missing 'prompt' or score column.\n",
            "\n",
            "Training for: gpt-3.5-turbo-1106\n",
            "\n",
            "🚀 FastText Regression Results for: gpt-3.5-turbo-1106\n",
            "Train MSE: 0.2215, MAE: 0.4467\n",
            "Test  MSE: 0.2227, MAE: 0.4473\n",
            "📦 FastText model saved to: /content/processed_data/gpt-3.5-turbo-1106/fasttext_regression_model.bin\n",
            "\n",
            "Training for: claude-v1\n",
            "\n",
            "🚀 FastText Regression Results for: claude-v1\n",
            "Train MSE: 0.1925, MAE: 0.4043\n",
            "Test  MSE: 0.2068, MAE: 0.4204\n",
            "📦 FastText model saved to: /content/processed_data/claude-v1/fasttext_regression_model.bin\n",
            "Skipping meta-llama-2-70b-chat: Missing 'prompt' or score column.\n",
            "\n",
            "Training for: gpt-4-1106-preview\n",
            "\n",
            "🚀 FastText Regression Results for: gpt-4-1106-preview\n",
            "Train MSE: 0.1681, MAE: 0.3678\n",
            "Test  MSE: 0.1776, MAE: 0.3781\n",
            "📦 FastText model saved to: /content/processed_data/gpt-4-1106-preview/fasttext_regression_model.bin\n",
            "Skipping WizardLM-WizardLM-13B-V1.2: Missing 'prompt' or score column.\n",
            "Skipping zero-one-ai-Yi-34B-Chat: Missing 'prompt' or score column.\n",
            "\n",
            "Training for: claude-v2\n",
            "\n",
            "🚀 FastText Regression Results for: claude-v2\n",
            "Train MSE: 0.1933, MAE: 0.4127\n",
            "Test  MSE: 0.2128, MAE: 0.4341\n",
            "📦 FastText model saved to: /content/processed_data/claude-v2/fasttext_regression_model.bin\n",
            "Skipping meta-code-llama-instruct-34b-chat: Missing 'prompt' or score column.\n",
            "\n",
            "Training for: claude-instant-v1\n",
            "\n",
            "🚀 FastText Regression Results for: claude-instant-v1\n",
            "Train MSE: 0.2209, MAE: 0.4455\n",
            "Test  MSE: 0.2222, MAE: 0.4468\n",
            "📦 FastText model saved to: /content/processed_data/claude-instant-v1/fasttext_regression_model.bin\n",
            "Skipping mistralai-mixtral-8x7b-chat: Missing 'prompt' or score column.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import os\n",
        "\n",
        "def patch_fasttext_predict():\n",
        "    from fasttext.FastText import _FastText\n",
        "    original_predict = _FastText.predict\n",
        "    def patched_predict(self, text, k=1, threshold=0.0):\n",
        "        labels, probs = original_predict(self, text, k, threshold)\n",
        "        return labels, np.asarray(probs)\n",
        "    _FastText.predict = patched_predict\n",
        "\n",
        "patch_fasttext_predict()  # 🛡 Apply the patch once\n",
        "\n",
        "def evaluate_fasttext_model_accuracy(train_file, test_file, model_path, model_name=\"FastText\"):\n",
        "    model = fasttext.load_model(model_path)\n",
        "\n",
        "    def get_predictions(file_path):\n",
        "        texts = [line.split(' ', 1)[1].strip() for line in open(file_path, encoding='utf-8')]\n",
        "        true_labels = [float(line.split(' ', 1)[0].replace('__label__', '')) for line in open(file_path, encoding='utf-8')]\n",
        "        pred_labels = [model.predict(text)[1][0] for text in texts]\n",
        "        return true_labels, pred_labels\n",
        "\n",
        "    def compute_accuracy(true, pred, tolerance=0.5):\n",
        "        rounded_acc = np.mean([round(t) == round(p) for t, p in zip(true, pred)])\n",
        "        within_tolerance = np.mean([abs(t - p) <= tolerance for t, p in zip(true, pred)])\n",
        "        return rounded_acc, within_tolerance\n",
        "\n",
        "    train_true, train_pred = get_predictions(train_file)\n",
        "    test_true, test_pred = get_predictions(test_file)\n",
        "\n",
        "    train_mse = mean_squared_error(train_true, train_pred)\n",
        "    test_mse = mean_squared_error(test_true, test_pred)\n",
        "    train_mae = mean_absolute_error(train_true, train_pred)\n",
        "    test_mae = mean_absolute_error(test_true, test_pred)\n",
        "\n",
        "    train_acc, train_tol_acc = compute_accuracy(train_true, train_pred)\n",
        "    test_acc, test_tol_acc = compute_accuracy(test_true, test_pred)\n",
        "\n",
        "    print(f\"\\n✅ Evaluation for model: {model_name}\")\n",
        "    print(f\"Train Accuracy (Rounded): {train_acc:.4f}, Within ±0.5: {train_tol_acc:.4f}\")\n",
        "    print(f\"Test  Accuracy (Rounded): {test_acc:.4f}, Within ±0.5: {test_tol_acc:.4f}\")\n",
        "    print(f\"Train MSE: {train_mse:.4f}, MAE: {train_mae:.4f}\")\n",
        "    print(f\"Test  MSE: {test_mse:.4f}, MAE: {test_mae:.4f}\")\n"
      ],
      "metadata": {
        "id": "HFD8x3R5Snge"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_fasttext_model_accuracy(\n",
        "    train_file='processed_data/gpt-3.5-turbo-1106/fasttext_train.txt',\n",
        "    test_file='processed_data/gpt-3.5-turbo-1106/fasttext_test.txt',\n",
        "    model_path='processed_data/gpt-3.5-turbo-1106/fasttext_regression_model.bin',\n",
        "    model_name='gpt-3.5-turbo-1106'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GkJnVqhSroe",
        "outputId": "84df8234-5383-48fc-d94e-6a5cab0d7870"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Evaluation for model: gpt-3.5-turbo-1106\n",
            "Train Accuracy (Rounded): 0.5000, Within ±0.5: 0.6226\n",
            "Test  Accuracy (Rounded): 0.5006, Within ±0.5: 0.6248\n",
            "Train MSE: 0.2215, MAE: 0.4467\n",
            "Test  MSE: 0.2227, MAE: 0.4473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_fasttext_model_accuracy(\n",
        "    train_file='/content/processed_data/claude-instant-v1/fasttext_train.txt',\n",
        "    test_file='/content/processed_data/claude-instant-v1/fasttext_test.txt',\n",
        "    model_path='/content/processed_data/claude-instant-v1/fasttext_regression_model.bin',\n",
        "    model_name='claude-instant-v1'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySDJQOs_T4V2",
        "outputId": "bc4ee6a2-19fa-4472-be9e-e60896faab10"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Evaluation for model: claude-instant-v1\n",
            "Train Accuracy (Rounded): 0.4744, Within ±0.5: 0.6276\n",
            "Test  Accuracy (Rounded): 0.4705, Within ±0.5: 0.6277\n",
            "Train MSE: 0.2209, MAE: 0.4455\n",
            "Test  MSE: 0.2222, MAE: 0.4468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_fasttext_model_accuracy(\n",
        "    train_file='/content/processed_data/gpt-4-1106-preview/fasttext_train.txt',\n",
        "    test_file='/content/processed_data/gpt-4-1106-preview/fasttext_test.txt',\n",
        "    model_path='/content/processed_data/gpt-4-1106-preview/fasttext_regression_model.bin',\n",
        "    model_name='gpt-4-1106-preview'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyAxzz8dUTcp",
        "outputId": "2acdb606-831b-4bb7-d772-edf69b6c93f2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Evaluation for model: gpt-4-1106-preview\n",
            "Train Accuracy (Rounded): 0.6307, Within ±0.5: 0.7829\n",
            "Test  Accuracy (Rounded): 0.6193, Within ±0.5: 0.7701\n",
            "Train MSE: 0.1681, MAE: 0.3678\n",
            "Test  MSE: 0.1776, MAE: 0.3781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_fasttext_model_accuracy(\n",
        "    train_file='/content/processed_data/claude-v2/fasttext_train.txt',\n",
        "    test_file='/content/processed_data/claude-v2/fasttext_test.txt',\n",
        "    model_path='/content/processed_data/claude-v2/fasttext_regression_model.bin',\n",
        "    model_name='claude-v2'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47a6ThbEUyMI",
        "outputId": "6d27e9dc-0c55-47b8-d8c6-8ff2ef34f61c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Evaluation for model: claude-v2\n",
            "Train Accuracy (Rounded): 0.5479, Within ±0.5: 0.7222\n",
            "Test  Accuracy (Rounded): 0.4895, Within ±0.5: 0.6659\n",
            "Train MSE: 0.1933, MAE: 0.4127\n",
            "Test  MSE: 0.2128, MAE: 0.4341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import fasttext\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# import pandas as pd\n",
        "import os\n",
        "import fasttext\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "import re\n",
        "\n",
        "# import fasttext\n",
        "# import numpy as np\n",
        "\n",
        "# Patch FastText to avoid NumPy 2.0 crash\n",
        "\n",
        "# Preprocess text: lowercase + remove punctuation\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "# Patch FastText model object AFTER training to fix NumPy issue\n",
        "def patch_predict(model):\n",
        "    original_predict = model.__class__.predict  # Get from the class, not from the instance\n",
        "\n",
        "    def safe_predict(self, text, k=1, threshold=0.0):\n",
        "        labels, probs = original_predict(self, text, k, threshold)\n",
        "        return labels, np.asarray(probs)\n",
        "\n",
        "    # Replace the method for this instance only\n",
        "    import types\n",
        "    model.predict = types.MethodType(safe_predict, model)\n",
        "\n",
        "\n",
        "\n",
        "def train_and_evaluate_fasttext(train_df, test_df, model_name, output_dir='processed_data'):\n",
        "    model_dir = os.path.join(output_dir, model_name.replace(\"/\", \"-\"))\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    train_file = os.path.join(model_dir, 'fasttext_train.txt')\n",
        "    test_file = os.path.join(model_dir, 'fasttext_test.txt')\n",
        "\n",
        "    # Ensure column names are usable\n",
        "    if 'prompt' not in train_df.columns or model_name not in train_df.columns:\n",
        "        raise ValueError(f\"Missing required columns in train_df: 'prompt' and '{model_name}'\")\n",
        "\n",
        "    # Create FastText format: __label__score <text>\n",
        "    train_df['fasttext_line'] = train_df.apply(\n",
        "        lambda x: f\"__label__{x[model_name]} {preprocess_text(x['prompt'])}\", axis=1\n",
        "    )\n",
        "    test_df['fasttext_line'] = test_df.apply(\n",
        "        lambda x: f\"__label__{x[model_name]} {preprocess_text(x['prompt'])}\", axis=1\n",
        "    )\n",
        "\n",
        "    train_df['fasttext_line'].to_csv(train_file, index=False, header=False, quoting=3, escapechar='\\\\')\n",
        "    test_df['fasttext_line'].to_csv(test_file, index=False, header=False, quoting=3, escapechar='\\\\')\n",
        "\n",
        "    # Train FastText model\n",
        "    model = fasttext.train_supervised(\n",
        "        input=train_file,\n",
        "        epoch=10,\n",
        "        lr=0.1,\n",
        "        wordNgrams=3,\n",
        "        loss='hs'\n",
        "    )\n",
        "\n",
        "    patch_predict(model)  # ✅ Fix NumPy predict crash\n",
        "\n",
        "    # Predict helper\n",
        "    def get_predictions(file_path, model):\n",
        "        texts = [line.split(' ', 1)[1].strip() for line in open(file_path, encoding='utf-8')]\n",
        "        true_labels = [float(line.split(' ', 1)[0].replace('__label__', '')) for line in open(file_path, encoding='utf-8')]\n",
        "        pred_labels = [model.predict(text)[1][0] for text in texts]\n",
        "        return true_labels, pred_labels\n",
        "\n",
        "    # Evaluate\n",
        "    train_true, train_pred = get_predictions(train_file, model)\n",
        "    test_true, test_pred = get_predictions(test_file, model)\n",
        "\n",
        "    train_mse = mean_squared_error(train_true, train_pred)\n",
        "    test_mse = mean_squared_error(test_true, test_pred)\n",
        "    train_mae = mean_absolute_error(train_true, train_pred)\n",
        "    test_mae = mean_absolute_error(test_true, test_pred)\n",
        "\n",
        "    acc_score = accuracy_score(train_true, train_pred)\n",
        "    print(f\"Accuracy Score: {acc_score}\")\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"\\n🚀 FastText Regression Results for: {model_name}\")\n",
        "\n",
        "    print(f\"Train MSE: {train_mse:.4f}, MAE: {train_mae:.4f}\")\n",
        "    print(f\"Test  MSE: {test_mse:.4f}, MAE: {test_mae:.4f}\")\n",
        "\n",
        "    # model.save_model(os.path.join(model_dir, 'fasttext_regression_model.bin'))\n",
        "    model_path = os.path.join(model_dir, 'fasttext_regression_model.bin')\n",
        "    model.save_model(model_path)\n",
        "    print(f\"📦 FastText model saved to: {model_path}\")\n",
        "\n",
        "def train_and_evaluate_distilbert(train_df, test_df, model_name, output_dir='processed_data'):\n",
        "    from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=1)\n",
        "    model.to(device)\n",
        "\n",
        "    # Prepare datasets\n",
        "    train_df['label'] = train_df[model_name].astype(float)\n",
        "    test_df['label'] = test_df[model_name].astype(float)\n",
        "\n",
        "    train_dataset = Dataset.from_pandas(train_df[['prompt', 'label']])\n",
        "    test_dataset = Dataset.from_pandas(test_df[['prompt', 'label']])\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(\n",
        "            examples['prompt'],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "    train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "    test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    # Define model output directory\n",
        "    model_output_dir = os.path.join(output_dir, model_name.replace(\"/\", \"-\") + \"-distilbert\")\n",
        "    os.makedirs(model_output_dir, exist_ok=True)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=model_output_dir,\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=32,\n",
        "        per_device_eval_batch_size=32,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        fp16=True,\n",
        "        load_best_model_at_end=True,\n",
        "        logging_dir=os.path.join(model_output_dir, \"logs\"),\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    def compute_metrics(eval_pred):\n",
        "      predictions, labels = eval_pred\n",
        "\n",
        "      # Ensure both are NumPy arrays\n",
        "      if hasattr(predictions, \"cpu\"):\n",
        "          predictions = predictions.cpu().numpy()\n",
        "      if hasattr(labels, \"cpu\"):\n",
        "          labels = labels.cpu().numpy()\n",
        "\n",
        "      predictions = predictions.squeeze()\n",
        "\n",
        "      mse = mean_squared_error(labels, predictions)\n",
        "      mae = mean_absolute_error(labels, predictions)\n",
        "      return {\"mse\": mse, \"mae\": mae}\n",
        "\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=test_dataset,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    print(f\"DistilBERT Regression - Test MSE: {eval_results['eval_mse']:.4f}, MAE: {eval_results['eval_mae']:.4f}\")\n",
        "\n",
        "    # ✅ Save model to unique folder\n",
        "    trainer.save_model(model_output_dir)\n",
        "    tokenizer.save_pretrained(model_output_dir)\n",
        "    print(f\"📦 DistilBERT model saved to: {model_output_dir}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # main(model_type=\"fasttext\")\n",
        "    main(model_type=\"distilbert\")  # Uncomment for DistilBERT\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687,
          "referenced_widgets": [
            "d41ecd21e9f5478682784c5231d37be8",
            "361f1af795e7496c82a74f72320fd31f",
            "6e5e35b0ee9b4c5f85aaa77ee4d990d9",
            "8af9871aab18478cadbdc922b4397959",
            "8da9d9d55f324aa08b5f2dfc3b6ee4d6",
            "315bbb24b766448ca399c404c569d286",
            "af29c2731314433b807476f82e5a7a9c",
            "a0793a6790384e809bb7894b147d7c82",
            "087e2b544f4c400daeca6f51ea9faac7",
            "ab987b620b29418fac9f54c9eedbc6f3",
            "60fec18a92144e4f804d57f8950374c3",
            "38c549ded6f846ce956ca02069066146",
            "5299298268ab4555b7632af2b1004288",
            "9f686bb7f5784c49a7ddd295c21e680d",
            "70e4ffc17e2b4178a1af0666d68af167",
            "db185fdfdbbc4871b20e17a6baf75bed",
            "bef0c28620fe48c5b6c3f6329f99cfc9",
            "9985037e314540b395e1f7c61c2b60df",
            "0be5e2a38df248419873cbee830f4e63",
            "69a163e578134af7bcf63c5471957b3a",
            "88c735eeb6194560a043c0e4e2f9b545",
            "1f4cf7cf87ae41459b8706bcc4977456",
            "213b71f1fd944edeb21c19eab0f0b7aa",
            "4a8556b7eb6e4499a8879dd3bc897bb6",
            "90116eb811ac492bb7d10a672ffa8eac",
            "2a20ea8e08804c3f861cd0672305c971",
            "5af5656dd0bb490ca0078d13a2176213",
            "d78fa6fe32b641c2b8a1520317d54f11",
            "0914dcfe8c6741878ed60ccb60f072b6",
            "d273cbb944424a339edaff94752d255a",
            "4772fa985bf1402dbba37b2ef6c669c4",
            "2cd8bf7965f94ebe8e466bcbba3c2398",
            "3d943749208746e4bbd051fd525788eb",
            "f5d5ce2a884c49378d31ab6674993ddd",
            "72ab8afb8c234108a205d6b32a98b5b4",
            "2165a60cc54e4ae2a087df5c0f00437a",
            "d19eb188716e4ed7a35b78eacd3d9eb0",
            "fb7f200b94dd4d418cf5fbb6fd52bc3d",
            "20f4cf8dd0914216ae45da6d5492b118",
            "b052d495ab7f4398b2f98cb595a3492b",
            "6c17ebcc2d3a4fb1814ebea9387e0488",
            "b0b198ffc9bb4403932da5c8effd1c2e",
            "938a9d020e7e4b6d8a313ea3b2970e45",
            "99a2f29d739c42aaa0d7de20640b7729"
          ]
        },
        "id": "kde7AgwIehgs",
        "outputId": "5619c4ef-d9d9-46d0-977b-f05f6e179227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping mistralai-mistral-7b-chat: Missing 'prompt' or score column.\n",
            "\n",
            "Training for: gpt-3.5-turbo-1106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/49996 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d41ecd21e9f5478682784c5231d37be8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/21428 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38c549ded6f846ce956ca02069066146"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4689' max='4689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4689/4689 34:57, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Mse</th>\n",
              "      <th>Mae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.166900</td>\n",
              "      <td>0.163029</td>\n",
              "      <td>0.163029</td>\n",
              "      <td>0.358227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.135800</td>\n",
              "      <td>0.142541</td>\n",
              "      <td>0.142541</td>\n",
              "      <td>0.291863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.076600</td>\n",
              "      <td>0.135556</td>\n",
              "      <td>0.135556</td>\n",
              "      <td>0.243822</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='670' max='670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [670/670 01:23]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT Regression - Test MSE: 0.1356, MAE: 0.2438\n",
            "📦 DistilBERT model saved to: /content/processed_data/gpt-3.5-turbo-1106-distilbert\n",
            "\n",
            "Training for: claude-v1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/49996 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "213b71f1fd944edeb21c19eab0f0b7aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/21428 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5d5ce2a884c49378d31ab6674993ddd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2983' max='4689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2983/4689 20:48 < 11:54, 2.39 it/s, Epoch 1.91/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Mse</th>\n",
              "      <th>Mae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.165300</td>\n",
              "      <td>0.164238</td>\n",
              "      <td>0.164238</td>\n",
              "      <td>0.335810</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import fasttext\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "\n",
        "# Set device to GPU if available (for DistilBERT)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)} for DistilBERT\")\n",
        "else:\n",
        "    print(\"No GPU available, DistilBERT falling back to CPU\")\n",
        "\n",
        "# Load DistilBERT model and tokenizer\n",
        "def load_distilbert_model(model_dir):\n",
        "    try:\n",
        "        tokenizer = DistilBertTokenizer.from_pretrained(model_dir)\n",
        "        model = DistilBertForSequenceClassification.from_pretrained(model_dir)\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading DistilBERT from {model_dir}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Predict score with DistilBERT\n",
        "def predict_distilbert_score(prompt, model, tokenizer):\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    score = outputs.logits.squeeze().item()\n",
        "    return max(0.0, min(1.0, score))\n",
        "\n",
        "# Load FastText model\n",
        "def load_fasttext_model(model_path):\n",
        "    try:\n",
        "        model = fasttext.load_model(model_path)\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading FastText from {model_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Predict score with FastText\n",
        "def predict_fasttext_score(prompt, model):\n",
        "    # FastText regression outputs a number directly\n",
        "    score = float(model.predict([prompt])[0][0])\n",
        "    return max(0.0, min(1.0, score))\n",
        "\n",
        "# Ensemble prediction\n",
        "def ensemble_score(distilbert_score, fasttext_score, weight_distilbert=0.5):\n",
        "    \"\"\"Combine scores with a weighted average.\"\"\"\n",
        "    weight_fasttext = 1.0 - weight_distilbert\n",
        "    ensemble = (weight_distilbert * distilbert_score) + (weight_fasttext * fasttext_score)\n",
        "    return ensemble\n",
        "\n",
        "def test_new_prompt(prompt, data_dir='/content/processed_data', weight_distilbert=0.5):\n",
        "    \"\"\"Test a prompt with ensembled DistilBERT and FastText models.\"\"\"\n",
        "    print(f\"\\nTesting prompt: '{prompt}'\")\n",
        "    scores = {}\n",
        "\n",
        "    for model_name in os.listdir(data_dir):\n",
        "        model_path = os.path.join(data_dir, model_name)\n",
        "        if not os.path.isdir(model_path):\n",
        "            continue\n",
        "\n",
        "        # Load DistilBERT\n",
        "        distilbert_dir = os.path.join(model_path, \"distilbert_model\")\n",
        "        distilbert_model, distilbert_tokenizer = None, None\n",
        "        if os.path.exists(distilbert_dir) and os.path.exists(os.path.join(distilbert_dir, \"pytorch_model.bin\")):\n",
        "            distilbert_model, distilbert_tokenizer = load_distilbert_model(distilbert_dir)\n",
        "\n",
        "        # Load FastText\n",
        "        fasttext_path = os.path.join(model_path, \"fasttext_model\", \"model.bin\")\n",
        "        fasttext_model = None\n",
        "        if os.path.exists(fasttext_path):\n",
        "            fasttext_model = load_fasttext_model(fasttext_path)\n",
        "\n",
        "        # Skip if neither model is available\n",
        "        if distilbert_model is None and fasttext_model is None:\n",
        "            print(f\"No models found for {model_name}\")\n",
        "            continue\n",
        "\n",
        "        # Predict scores\n",
        "        distilbert_score = None\n",
        "        if distilbert_model and distilbert_tokenizer:\n",
        "            distilbert_score = predict_distilbert_score(prompt, distilbert_model, distilbert_tokenizer)\n",
        "            print(f\"{model_name} (DistilBERT): {distilbert_score:.4f}\")\n",
        "\n",
        "        fasttext_score = None\n",
        "        if fasttext_model:\n",
        "            fasttext_score = predict_fasttext_score(prompt, fasttext_model)\n",
        "            print(f\"{model_name} (FastText): {fasttext_score:.4f}\")\n",
        "\n",
        "        # Ensemble if both available, else use available one\n",
        "        if distilbert_score is not None and fasttext_score is not None:\n",
        "            final_score = ensemble_score(distilbert_score, fasttext_score, weight_distilbert)\n",
        "            print(f\"{model_name} (Ensemble): {final_score:.4f}\")\n",
        "            scores[model_name] = final_score\n",
        "        elif distilbert_score is not None:\n",
        "            print(f\"{model_name} (Only DistilBERT available): {distilbert_score:.4f}\")\n",
        "            scores[model_name] = distilbert_score\n",
        "        elif fasttext_score is not None:\n",
        "            print(f\"{model_name} (Only FastText available): {fasttext_score:.4f}\")\n",
        "            scores[model_name] = fasttext_score\n",
        "\n",
        "    return scores\n",
        "\n",
        "def main():\n",
        "    new_prompt = \"Explain relativity simply\"\n",
        "    scores = test_new_prompt(new_prompt, data_dir='/content/processed_data', weight_distilbert=0.5)\n",
        "    if scores:\n",
        "        best_llm = max(scores, key=scores.get)\n",
        "        print(f\"\\nBest LLM for '{new_prompt}': {best_llm} with ensemble score {scores[best_llm]:.4f}\")\n",
        "\n",
        "if _name_ == \"_main_\":\n",
        "    main"
      ],
      "metadata": {
        "id": "UkUPc9wryfJ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}